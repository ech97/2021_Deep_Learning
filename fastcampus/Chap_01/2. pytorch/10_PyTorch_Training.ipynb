{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bittensorflowvenv10b5cbcd7cd74bb9aca26b9edce6abe3",
   "display_name": "Python 3.7.8 64-bit ('tensorflow': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1 # 셔플 고정\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset', train=True, download=True, transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size = batch_size, shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('dataset', train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307, ), (0.3081, ))])),\n",
    "batch_size = test_batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.reshape(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([20, 1, 5, 5])\ntorch.Size([20])\ntorch.Size([50, 20, 5, 5])\ntorch.Size([50])\ntorch.Size([500, 800])\ntorch.Size([500])\ntorch.Size([10, 500])\ntorch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.5)\n",
    "\n",
    "\n",
    "# 모델을 구성하고있는 파라미터들의 사이즈를 확인할수있음\n",
    "# Weight(커널)), Bias(층을 통과 나고 여러 채널로 나올때 영향을 주는 값 같음)\n",
    "params = list(model.parameters())\n",
    "\n",
    "for i in range(8):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# train mode로 변환\n",
    "model.train()\n",
    "\n",
    "data, target = next(iter(train_loader)) #64배치씩 하나한  가져오기\n",
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 데이터를 gpu에 컴파일\n",
    "data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradients를 clear해서 새로운 최적화값을 찾기위해 준비\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측해보기\n",
    "output = model(data)\n",
    "\n",
    "# 모델에서 출력한 결과를 원본과비교해서 얼마나 틀렸는지 계산\n",
    "loss = F.nll_loss(output, target) #Log_Likelihood Loss\n",
    "\n",
    "# Back Propagation을 통해 Gradients(기여율)를 계산\n",
    "loss.backward()\n",
    "\n",
    "# 계산된 Gradient를 optim에 넣어줘서 optim를 업뎃해야함\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper param 조정\n",
    "epochs = 2\n",
    "log_interval = 100 # 수학 log가 아닌 남는 log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.430903\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.375004\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.519534\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.373206\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.328481\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.432391\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.312596\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.252729\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.419630\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.233712\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.350878\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.430641\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.293073\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.304014\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.271215\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.221577\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.406958\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.160343\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.291036\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.137508\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    # train모드로 변경\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device) # 뽑은 데이터를 device에 컴파일\n",
    "        optimizer.zero_grad() # 기여율 초기화\n",
    "        output = model(data) # 모델에 데이터 삽입하여 예측\n",
    "        loss = F.nll_loss(output, target)  # 예측 결과를 target과 비교하여 오차 계산\n",
    "        loss.backward() # 발생한 오차에 대해 오차의 얼만큼을 기여했는지 계산한걸로, 그만큼 lr을 곱해 weight에서 빼줌\n",
    "        optimizer.step() # 옵티마이저에 변경된 weight 업뎃\n",
    "\n",
    "        # 학습 1번 완료\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100 * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "source": [
    "# Evaluation (평가)\n",
    "- 앞에서 model.train() 하여 train모드로 변경했던거 처럼, model.eval()로 설정하여 평가모드로 변경\n",
    "- Batch Normalization이나 Drop Out 같은 레이어를 잠그고 실행"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# 평가하는 행방법\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# Back Propagation이나 Gradient같은 계산을 꺼서, 속도 높아짐 // 평가땐 필요없으니깐 걍 꺼\n",
    "with torch.no_grad():\n",
    "    data, target = next(iter(test_loader)) # 평가용 데이터(사진, 라벨) 로드\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data) # 예측\n",
    "\n",
    "    # 평가할때는 오차를 Back propagation 할 필요없음\n",
    "    # 근데 일단 예측 결과와 target과의 차이 계산\n",
    "    test_loss += F.nll_loss(output, target, reduction='sum').item() # reduction을 이용해 하나의 Scala로 만들어줌\n",
    "     \n",
    "    pred = output.argmax(dim=1, keepdim = True) # 예측 결과들(확률들) 중에 가장 큰\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item() # target과 pred가 같은지 체크 ==> True/False // 근데 이게 배치개수만큼 결과가 나오니깐 sum으로 True를 다 합해버려\n",
    "    # 이때 view_as함수를 써서 target 얘가 pred의 행렬꼴과 같에 reshape해줌\n",
    "    \n",
    "    # argmax는 dim = 1이면 (가로) 64개의 이미지중 하나, 하나의 결과 10개 중 가장 큰 값의 idx를 나타냄. 총 64개를 나타내는데 이때 64개를 나타낼때, 차원을 기존 output의 차원인 2차원을 유지\n",
    "    # 만약 dim = 0이면 (세로) 64개가 아닌 10개로 나타남\n",
    "    \n",
    "    # item()은 숫자값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.1899e+01, -9.5890e+00, -6.0238e+00, -8.8951e+00, -8.9397e+00,\n",
       "         -7.1883e+00, -8.3142e+00, -8.6594e+00, -5.5478e-03, -6.4410e+00],\n",
       "        [-8.5849e+00, -5.6182e-02, -5.0977e+00, -5.2562e+00, -5.5690e+00,\n",
       "         -5.1753e+00, -4.9602e+00, -5.0022e+00, -4.1791e+00, -5.3807e+00],\n",
       "        [-4.1546e+00, -4.0111e+00, -4.3177e+00, -2.5835e-01, -8.9893e+00,\n",
       "         -1.8700e+00, -6.6589e+00, -6.0079e+00, -3.8755e+00, -6.3191e+00],\n",
       "        [-1.2150e+01, -1.3669e+01, -8.2551e+00, -9.5405e-04, -1.7383e+01,\n",
       "         -8.3825e+00, -1.7593e+01, -1.3933e+01, -7.7166e+00, -1.1316e+01],\n",
       "        [-5.2426e+00, -1.3423e+01, -2.4755e+00, -5.5567e+00, -1.7364e+01,\n",
       "         -8.7043e+00, -1.5730e+01, -1.0536e-01, -5.5563e+00, -5.9148e+00],\n",
       "        [-5.3765e+00, -9.1437e+00, -3.7044e+00, -9.9278e+00, -2.0153e-01,\n",
       "         -6.4189e+00, -2.2719e+00, -6.1236e+00, -4.5307e+00, -3.3404e+00],\n",
       "        [-1.1147e-03, -2.5111e+01, -1.1292e+01, -1.1943e+01, -2.1941e+01,\n",
       "         -6.8255e+00, -1.2733e+01, -1.5200e+01, -1.2136e+01, -1.4127e+01],\n",
       "        [-6.7960e+00, -1.1827e+01, -1.7989e+00, -4.5159e+00, -1.6868e+01,\n",
       "         -1.0922e+01, -1.6864e+01, -2.0866e-01, -6.2778e+00, -4.7234e+00],\n",
       "        [-6.0827e-03, -1.4425e+01, -7.6706e+00, -8.3980e+00, -1.0097e+01,\n",
       "         -5.8666e+00, -8.1392e+00, -7.7737e+00, -7.6498e+00, -6.6380e+00],\n",
       "        [-5.6602e+00, -1.5461e+01, -5.2823e+00, -1.1923e+01, -1.0485e+01,\n",
       "         -6.9231e+00, -1.7123e-02, -1.5107e+01, -4.9075e+00, -1.2633e+01],\n",
       "        [-1.7207e+01, -1.6742e+01, -1.4865e+01, -1.2175e+01, -1.6427e+01,\n",
       "         -1.5700e+01, -2.3122e+01, -5.4476e-04, -1.3471e+01, -7.5288e+00],\n",
       "        [-9.8974e+00, -1.7574e+01, -1.2365e+01, -8.6814e+00, -5.0457e+00,\n",
       "         -7.7678e+00, -1.4176e+01, -3.3343e-01, -8.9529e+00, -1.2862e+00],\n",
       "        [-1.1744e+01, -1.0496e+01, -5.9703e-02, -2.8786e+00, -8.0144e+00,\n",
       "         -1.0033e+01, -7.7674e+00, -1.2475e+01, -7.2339e+00, -8.6048e+00],\n",
       "        [-1.1819e+01, -1.1551e+01, -1.1310e+01, -8.7912e+00, -5.7625e+00,\n",
       "         -9.6840e+00, -1.5422e+01, -1.3004e+00, -8.6708e+00, -3.2293e-01],\n",
       "        [-7.9973e+00, -9.1205e+00, -5.1467e+00, -5.9361e+00, -7.3652e+00,\n",
       "         -4.5402e+00, -9.7025e+00, -8.4240e+00, -2.7968e-02, -4.9493e+00],\n",
       "        [-1.5168e-02, -1.6314e+01, -5.6210e+00, -7.3396e+00, -1.2989e+01,\n",
       "         -4.7188e+00, -7.7283e+00, -8.2826e+00, -7.0625e+00, -8.0949e+00],\n",
       "        [-7.4293e+00, -1.0747e+01, -6.6591e+00, -4.1900e+00, -3.2703e+00,\n",
       "         -1.8215e-01, -3.9346e+00, -8.7460e+00, -3.5010e+00, -2.7870e+00],\n",
       "        [-9.1393e+00, -4.1109e+00, -1.2205e-01, -2.7368e+00, -6.9711e+00,\n",
       "         -8.9055e+00, -8.0863e+00, -5.6169e+00, -5.5651e+00, -3.6980e+00],\n",
       "        [-9.7032e+00, -9.2923e+00, -7.0029e+00, -3.5676e+00, -1.3434e+01,\n",
       "         -4.2052e-02, -1.0268e+01, -1.2586e+01, -4.4386e+00, -1.0062e+01],\n",
       "        [-1.1105e+01, -6.0972e+00, -2.3731e+00, -6.1776e+00, -3.1418e+00,\n",
       "         -6.7456e+00, -1.5869e-01, -9.1207e+00, -5.5113e+00, -7.3045e+00],\n",
       "        [-1.0961e+01, -1.4946e+01, -1.0032e+01, -8.7985e+00, -1.2301e+01,\n",
       "         -6.7460e+00, -1.2147e+01, -1.3150e+01, -1.8206e-03, -7.7780e+00],\n",
       "        [-1.8070e-04, -2.4415e+01, -1.0405e+01, -1.4280e+01, -1.8577e+01,\n",
       "         -9.2373e+00, -9.9229e+00, -1.6307e+01, -1.2756e+01, -1.4739e+01],\n",
       "        [-6.2122e+00, -1.5181e+01, -5.4928e+00, -4.1515e+00, -8.2515e+00,\n",
       "         -2.9168e+00, -7.3794e+00, -9.9431e+00, -9.0861e-02, -4.6100e+00],\n",
       "        [-1.0945e+01, -1.0637e+01, -9.4915e+00, -8.6827e+00, -1.2297e+01,\n",
       "         -1.1098e+01, -1.8306e+01, -2.0402e-02, -7.9108e+00, -3.9362e+00],\n",
       "        [-5.7424e+00, -3.9415e+00, -4.5698e-01, -2.4970e+00, -1.1900e+01,\n",
       "         -8.1634e+00, -7.6239e+00, -9.9455e+00, -1.3435e+00, -9.3055e+00],\n",
       "        [-1.6680e+01, -1.5131e+01, -1.0103e+01, -2.0657e-04, -1.6029e+01,\n",
       "         -1.0395e+01, -1.8278e+01, -1.3796e+01, -9.1220e+00, -1.0628e+01],\n",
       "        [-7.3628e+00, -4.9566e+00, -3.4894e+00, -6.6227e+00, -3.7110e+00,\n",
       "         -3.9557e+00, -1.3376e-01, -9.5958e+00, -3.1982e+00, -6.7451e+00],\n",
       "        [-1.2422e+01, -9.9249e+00, -9.1259e+00, -1.4891e-01, -1.0340e+01,\n",
       "         -2.0032e+00, -8.8205e+00, -1.0120e+01, -6.0037e+00, -7.4146e+00],\n",
       "        [-1.6286e+00, -1.6860e+01, -2.3911e-01, -9.3291e+00, -1.5496e+01,\n",
       "         -4.5549e+00, -5.5939e+00, -9.9004e+00, -6.1875e+00, -9.9675e+00],\n",
       "        [-1.1415e+01, -1.6003e+01, -1.2450e+01, -1.1927e+01, -1.7771e+00,\n",
       "         -1.0060e+01, -1.2391e+01, -4.9639e+00, -8.3942e+00, -1.9408e-01],\n",
       "        [-1.7702e+01, -2.1494e+01, -1.8648e+01, -1.1231e+01, -1.8450e+01,\n",
       "         -1.6163e+01, -2.5982e+01, -2.7748e-04, -1.6852e+01, -8.2395e+00],\n",
       "        [-8.9884e+00, -1.2400e+00, -3.1841e+00, -9.5899e-01, -7.7380e+00,\n",
       "         -2.4499e+00, -7.5384e+00, -4.8883e+00, -1.7442e+00, -4.1220e+00],\n",
       "        [-5.2333e+00, -1.4307e+01, -5.2724e+00, -7.7836e+00, -2.8460e+00,\n",
       "         -6.2228e+00, -6.2496e+00, -4.4184e+00, -7.1072e+00, -8.9647e-02],\n",
       "        [-7.5888e+00, -1.5458e+01, -6.8376e+00, -5.9860e+00, -2.0175e+01,\n",
       "         -6.1318e-03, -9.4970e+00, -1.8879e+01, -6.2424e+00, -1.5406e+01],\n",
       "        [-1.1986e+01, -1.8353e+01, -8.9448e+00, -3.7568e+00, -1.2735e+01,\n",
       "         -2.4899e-02, -1.1415e+01, -1.3946e+01, -6.9843e+00, -8.7705e+00],\n",
       "        [-4.8437e+00, -1.1484e+01, -4.4732e+00, -9.9492e+00, -6.6664e+00,\n",
       "         -2.3725e+00, -1.2122e-01, -1.4143e+01, -8.1765e+00, -1.2197e+01],\n",
       "        [-1.4195e+01, -7.5985e+00, -9.4409e+00, -2.0752e-02, -8.4227e+00,\n",
       "         -5.2825e+00, -1.2525e+01, -6.8802e+00, -6.0306e+00, -4.4900e+00],\n",
       "        [-9.8784e+00, -1.2502e+01, -9.7330e-03, -7.2958e+00, -6.4866e+00,\n",
       "         -1.0530e+01, -8.1512e+00, -7.4893e+00, -6.6782e+00, -5.2407e+00],\n",
       "        [-1.2512e+01, -1.2913e+01, -9.6734e+00, -8.7812e+00, -1.3452e-02,\n",
       "         -9.1565e+00, -9.4972e+00, -7.9459e+00, -9.5474e+00, -4.3794e+00],\n",
       "        [-1.4822e+01, -3.0668e-03, -9.0925e+00, -6.6857e+00, -8.8726e+00,\n",
       "         -8.7794e+00, -9.6411e+00, -8.1405e+00, -7.3686e+00, -7.7770e+00],\n",
       "        [-1.0688e+01, -8.3301e+00, -9.1866e+00, -3.7138e+00, -4.8700e+00,\n",
       "         -3.7924e+00, -1.0081e+01, -3.3810e-01, -6.5818e+00, -1.4676e+00],\n",
       "        [-1.3249e+01, -1.1738e+01, -1.1090e+01, -1.3366e-02, -1.1728e+01,\n",
       "         -5.0034e+00, -1.5947e+01, -7.4195e+00, -6.4066e+00, -5.4541e+00],\n",
       "        [-1.4453e+01, -1.2185e+01, -3.9262e+00, -2.8710e+00, -8.5415e-01,\n",
       "         -7.5228e+00, -8.3623e+00, -7.3689e+00, -5.7021e+00, -7.0675e-01],\n",
       "        [-1.4140e+01, -1.2718e+01, -1.0194e+01, -4.8620e+00, -2.5565e+00,\n",
       "         -5.5757e+00, -1.1222e+01, -6.2108e+00, -5.2473e+00, -1.0139e-01],\n",
       "        [-3.2719e+00, -9.3457e+00, -9.1806e+00, -1.0315e+01, -5.2045e+00,\n",
       "         -6.7189e-02, -4.4543e+00, -7.7573e+00, -4.7438e+00, -7.4718e+00],\n",
       "        [-1.3592e+01, -1.2502e+01, -1.0221e+01, -7.3244e+00, -2.3812e+00,\n",
       "         -8.6500e+00, -1.1560e+01, -7.0439e+00, -5.9051e+00, -1.0194e-01],\n",
       "        [-9.9083e+00, -4.9896e+00, -4.8217e+00, -6.9766e+00, -7.5073e+00,\n",
       "         -5.4794e+00, -6.3507e+00, -9.6604e+00, -2.4006e-02, -6.6114e+00],\n",
       "        [-1.4072e+01, -1.2527e+01, -1.1849e+01, -1.2903e+01, -3.1107e-03,\n",
       "         -1.0400e+01, -8.9498e+00, -8.7448e+00, -8.9205e+00, -5.9375e+00],\n",
       "        [-9.5317e-03, -2.1183e+01, -1.3446e+01, -7.6362e+00, -1.6481e+01,\n",
       "         -4.7502e+00, -1.4416e+01, -8.3215e+00, -1.0868e+01, -9.3188e+00],\n",
       "        [-1.4634e+01, -1.0754e+01, -1.3152e+01, -8.9252e+00, -1.0197e+01,\n",
       "         -1.2694e+01, -1.8015e+01, -4.0937e-03, -1.1290e+01, -5.5530e+00],\n",
       "        [-1.8196e+01, -9.7686e+00, -7.4387e+00, -5.1716e+00, -7.9792e+00,\n",
       "         -1.3220e+01, -1.5066e+01, -6.3773e-02, -9.0428e+00, -2.9005e+00],\n",
       "        [-1.7294e+01, -9.5796e+00, -1.0115e-03, -7.0471e+00, -1.5479e+01,\n",
       "         -1.5974e+01, -1.2611e+01, -9.8685e+00, -1.1178e+01, -1.2884e+01],\n",
       "        [-1.2578e+01, -1.0801e+01, -1.0372e+01, -1.0468e+01, -2.3670e-01,\n",
       "         -8.3755e+00, -9.9680e+00, -7.2724e+00, -4.1579e+00, -1.6395e+00],\n",
       "        [-1.5231e-02, -1.5082e+01, -6.3859e+00, -6.2607e+00, -1.5471e+01,\n",
       "         -5.1311e+00, -1.1300e+01, -6.4112e+00, -6.3956e+00, -6.0811e+00],\n",
       "        [-1.0788e+01, -2.0047e-02, -5.2697e+00, -6.1297e+00, -8.1978e+00,\n",
       "         -1.0411e+01, -9.2736e+00, -4.7137e+00, -5.8934e+00, -7.8842e+00],\n",
       "        [-1.2840e+01, -9.7477e+00, -1.3613e+01, -6.5149e+00, -6.8068e+00,\n",
       "         -8.4955e+00, -1.6859e+01, -2.0390e+00, -7.1236e+00, -1.4366e-01],\n",
       "        [-1.2508e+01, -1.7827e+00, -2.3484e-01, -4.7161e+00, -1.5505e+01,\n",
       "         -1.0379e+01, -7.3501e+00, -1.1472e+01, -3.4587e+00, -1.2803e+01],\n",
       "        [-1.5305e+01, -1.9856e+00, -2.1789e-01, -2.8626e+00, -1.4818e+01,\n",
       "         -1.0408e+01, -7.5157e+00, -9.3329e+00, -7.2575e+00, -1.3629e+01],\n",
       "        [-6.3434e+00, -1.5110e+00, -3.9567e+00, -4.4048e+00, -8.0790e+00,\n",
       "         -3.4669e+00, -5.2216e+00, -6.3739e+00, -3.5037e-01, -5.7581e+00],\n",
       "        [-1.6512e+01, -1.0365e+01, -1.0865e+01, -6.0128e+00, -3.0979e+00,\n",
       "         -9.2603e+00, -1.2990e+01, -6.0131e+00, -6.3839e+00, -5.3269e-02],\n",
       "        [-1.1419e+01, -1.1985e+01, -4.5210e+00, -4.8935e+00, -1.0298e+01,\n",
       "         -6.2342e+00, -9.3645e+00, -1.1540e+01, -2.0973e-02, -8.2052e+00],\n",
       "        [-1.2007e+01, -1.7700e-02, -5.2788e+00, -6.3798e+00, -1.1478e+01,\n",
       "         -8.6629e+00, -9.5288e+00, -5.0219e+00, -5.7301e+00, -7.3398e+00],\n",
       "        [-5.9587e+00, -1.3481e+01, -1.3542e+00, -3.7230e-01, -1.2852e+01,\n",
       "         -6.7451e+00, -8.7822e+00, -9.3672e+00, -3.0496e+00, -6.6280e+00],\n",
       "        [-9.4233e+00, -1.1639e+01, -9.5001e+00, -6.2543e-03, -1.4093e+01,\n",
       "         -5.1922e+00, -1.3635e+01, -1.0740e+01, -7.7381e+00, -9.8783e+00]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    " # 7 분부터 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}